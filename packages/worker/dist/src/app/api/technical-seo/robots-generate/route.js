"use strict";
Object.defineProperty(exports, "__esModule", { value: true });
exports.dynamic = void 0;
exports.POST = POST;
exports.GET = GET;
const server_1 = require("next/server");
const supabase_js_1 = require("@supabase/supabase-js");
// Force dynamic rendering
exports.dynamic = 'force-dynamic';
const supabase = (0, supabase_js_1.createClient)(process.env.NEXT_PUBLIC_SUPABASE_URL, process.env.SUPABASE_SERVICE_ROLE_KEY);
async function POST(request) {
    try {
        const { website_token, domain } = await request.json();
        if (!website_token && !domain) {
            return server_1.NextResponse.json({
                error: 'Missing required parameters: website_token or domain'
            }, { status: 400 });
        }
        console.log('[ROBOTS GENERATE] Generating robots.txt for:', domain || 'token-based request');
        // Get website info if we have a token
        let websiteData = null;
        if (website_token) {
            const { data: website } = await supabase
                .from('websites')
                .select('*')
                .eq('website_token', website_token)
                .single();
            websiteData = website;
        }
        // Generate robots.txt content
        const robotsContent = generateRobotsContent(domain || websiteData?.domain || 'example.com');
        // Store in database if we have website info
        if (websiteData) {
            const { error: insertError } = await supabase
                .from('robots_analyses')
                .upsert({
                user_token: websiteData.user_token,
                site_url: websiteData.url || `https://${domain}`,
                exists: true,
                accessible: true,
                size: robotsContent.length,
                content: robotsContent,
                issues: [],
                suggestions: [],
                crawl_delay: null,
                sitemap_urls: [`https://${domain || websiteData.domain}/sitemap.xml`],
                user_agents: ['*'],
                allowed_paths: ['/'],
                disallowed_paths: ['/admin/', '/wp-admin/', '/search', '/*?*'],
                analyzed_at: new Date().toISOString()
            }, {
                onConflict: 'user_token,site_url'
            });
            if (insertError) {
                console.error('[ROBOTS GENERATE] Database error:', insertError);
            }
            else {
                console.log('[ROBOTS GENERATE] Stored robots.txt analysis in database');
            }
        }
        return server_1.NextResponse.json({
            success: true,
            robotsContent,
            domain: domain || websiteData?.domain
        });
    }
    catch (error) {
        console.error('[ROBOTS GENERATE] Error:', error);
        return server_1.NextResponse.json({
            error: 'Internal server error'
        }, { status: 500 });
    }
}
async function GET(request) {
    const domain = request.nextUrl.searchParams.get('domain');
    if (!domain) {
        return server_1.NextResponse.json({
            error: 'Missing domain parameter'
        }, { status: 400 });
    }
    const robotsContent = generateRobotsContent(domain);
    return new Response(robotsContent, {
        headers: {
            'Content-Type': 'text/plain; charset=utf-8',
            'Cache-Control': 'public, max-age=3600' // Cache for 1 hour
        }
    });
}
function generateRobotsContent(domain) {
    const currentDate = new Date().toISOString().split('T')[0];
    const protocol = domain.startsWith('localhost') ? 'http' : 'https';
    const sitemapUrl = `${protocol}://${domain}/sitemap.xml`;
    return `# Robots.txt generated by SEOAgent.js
# Learn more: https://seoagent.com
# Generated on: ${currentDate}

User-agent: *
Allow: /

# Sitemap location (automatically updated)
Sitemap: ${sitemapUrl}

# Block common admin and development areas
Disallow: /admin/
Disallow: /wp-admin/
Disallow: /wp-includes/
Disallow: /wp-content/plugins/
Disallow: /wp-content/cache/
Disallow: /wp-content/themes/*/inc/

# Block search and filter pages to avoid duplicate content
Disallow: /search
Disallow: /*?*
Disallow: /*&*

# Block development and staging areas
Disallow: /dev/
Disallow: /test/
Disallow: /staging/
Disallow: /_dev/
Disallow: /_test/
Disallow: /.git/
Disallow: /.env

# Block common CMS admin paths
Disallow: /administrator/
Disallow: /panel/
Disallow: /cms/
Disallow: /dashboard/
Disallow: /control-panel/

# Block common e-commerce paths that shouldn't be indexed
Disallow: /cart/
Disallow: /checkout/
Disallow: /account/
Disallow: /login/
Disallow: /register/
Disallow: /my-account/

# Block tracking and analytics
Disallow: /analytics/
Disallow: /stats/
Disallow: /metrics/

# Block API endpoints (uncomment if you don't want them indexed)
# Disallow: /api/
# Disallow: /rest/
# Disallow: /graphql/

# Allow important files and assets
Allow: /robots.txt
Allow: /sitemap.xml
Allow: /*.css$
Allow: /*.js$
Allow: /*.jpg$
Allow: /*.jpeg$
Allow: /*.png$
Allow: /*.gif$
Allow: /*.svg$
Allow: /*.webp$
Allow: /*.ico$

# SEO-friendly rules for better crawling
# Allow social media files
Allow: /facebook-domain-verification.html
Allow: /googleXXXXXXXXXXXXXXXX.html
Allow: /BingSiteAuth.xml
Allow: /yandex_XXXXXXXXXXXXXXX.html

# Generated by SEOAgent.js - Automated SEO Platform
# Visit https://seoagent.com for more SEO automation tools
`;
}
